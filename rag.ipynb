{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83ce94e",
   "metadata": {},
   "source": [
    "# RAG with llm model(llama3.2)+qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b0353",
   "metadata": {},
   "source": [
    "PDF Upload\n",
    "\n",
    "    ↓\n",
    "\n",
    "Extract Text from PDF(PyPDF2)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Chunk Text (500 characters, 50 overlap)(RecursiveCharacterTextSplitter)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Embed Chunks (MiniLM → 384-d vectors)(all-MiniLM-L6-v2)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Store Embeddings in Qdrant (rag_collection)\n",
    "__________________________________________________________________________________________________________\n",
    "User Query\n",
    "\n",
    "    ↓\n",
    "\n",
    "Convert Query to Embedding (same model: all-MiniLM-L6-v2)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Similarity Search in Qdrant (top-k = 3, score_threshold = 0.5)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Retrieve Relevant Chunks (as context)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Insert into Custom Prompt (context + question)\n",
    "\n",
    "    ↓\n",
    "\n",
    "LLM Inference (llama3.2)\n",
    "\n",
    "    ↓\n",
    "\n",
    "Generate Final Answer\n",
    "\n",
    "    ↓\n",
    "\n",
    "Return Answer + Retrieved Chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc69983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./myenv/lib/python3.12/site-packages (0.3.25)\n",
      "Requirement already satisfied: qdrant-client in ./myenv/lib/python3.12/site-packages (1.14.2)\n",
      "Requirement already satisfied: sentence-transformers in ./myenv/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: ollama in ./myenv/lib/python3.12/site-packages (0.4.8)\n",
      "Requirement already satisfied: gradio in ./myenv/lib/python3.12/site-packages (5.29.0)\n",
      "Requirement already satisfied: pypdf2 in ./myenv/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: tiktoken in ./myenv/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: langchain-ollama in ./myenv/lib/python3.12/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-huggingface in ./myenv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain-qdrant in ./myenv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./myenv/lib/python3.12/site-packages (from langchain) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./myenv/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./myenv/lib/python3.12/site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./myenv/lib/python3.12/site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./myenv/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in ./myenv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./myenv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in ./myenv/lib/python3.12/site-packages (from qdrant-client) (1.71.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in ./myenv/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.26 in ./myenv/lib/python3.12/site-packages (from qdrant-client) (2.2.5)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in ./myenv/lib/python3.12/site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in ./myenv/lib/python3.12/site-packages (from qdrant-client) (6.30.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./myenv/lib/python3.12/site-packages (from qdrant-client) (2.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./myenv/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in ./myenv/lib/python3.12/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./myenv/lib/python3.12/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in ./myenv/lib/python3.12/site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in ./myenv/lib/python3.12/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.10.0 in ./myenv/lib/python3.12/site-packages (from gradio) (1.10.0)\n",
      "Requirement already satisfied: groovy~=0.1 in ./myenv/lib/python3.12/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: jinja2<4.0 in ./myenv/lib/python3.12/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in ./myenv/lib/python3.12/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in ./myenv/lib/python3.12/site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.12/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in ./myenv/lib/python3.12/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pydub in ./myenv/lib/python3.12/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in ./myenv/lib/python3.12/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in ./myenv/lib/python3.12/site-packages (from gradio) (0.11.8)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in ./myenv/lib/python3.12/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in ./myenv/lib/python3.12/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in ./myenv/lib/python3.12/site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in ./myenv/lib/python3.12/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in ./myenv/lib/python3.12/site-packages (from gradio) (0.15.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in ./myenv/lib/python3.12/site-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.12/site-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in ./myenv/lib/python3.12/site-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./myenv/lib/python3.12/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in ./myenv/lib/python3.12/site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./myenv/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./myenv/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in ./myenv/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in ./myenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./myenv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./myenv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./myenv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./myenv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./myenv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./myenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./myenv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: click>=8.0.0 in ./myenv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./myenv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./myenv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in ./myenv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in ./myenv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./myenv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain qdrant-client sentence-transformers ollama gradio pypdf2 tiktoken -U langchain-ollama langchain-huggingface langchain-qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a288748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d646f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='rag_collection')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2037/546241334.py:21: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use :class:`~QdrantVectorStore` instead.\n",
      "  vectorstore = Qdrant(\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "embeddings_model= HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "try:\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=\"rag_collection\",\n",
    "        vectors_config={\n",
    "            \"size\": 384,\n",
    "            \"distance\": \"Cosine\"\n",
    "        },\n",
    "        optimizers_config={\"default_segment_number\": 1},\n",
    "        on_disk_payload=True\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "vectorstore = Qdrant(\n",
    "    client=qdrant_client,\n",
    "    collection_name=\"rag_collection\",\n",
    "    embeddings=embeddings_model\n",
    ")\n",
    "collections = qdrant_client.get_collections()\n",
    "print(collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0b1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file):\n",
    "    reader = PdfReader(file)\n",
    "    text = \"\\n\".join([page.extract_text() for page in reader.pages])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a7f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(text):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "def store_embeddings(text_chunks, file_id):\n",
    "    vectorstore.add_texts(\n",
    "        texts=text_chunks,\n",
    "        metadatas=[{\"file_id\": file_id}] * len(text_chunks)\n",
    "    )\n",
    "\n",
    "def delete_collection(collection_name=\"rag_collection\"):\n",
    "    try:\n",
    "        qdrant_client.delete_collection(collection_name=collection_name)\n",
    "        print(f\"Collection '{collection_name}' deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting collection: {e}\")\n",
    "\n",
    "\n",
    "#def delete_by_file_id(file_id):\n",
    "#   qdrant_client.delete(\n",
    "#       collection_name=\"rag_collection\",\n",
    "#        filter={\n",
    "#            \"must\": [\n",
    "#                {\"key\": \"file_id\", \"match\": {\"value\": file_id}}\n",
    "#            ]\n",
    "#        }\n",
    "#    )\n",
    "\n",
    "\n",
    "# from qdrant_client.http import models as rest\n",
    "# #Function to delete existing chunks for a given file_idff\n",
    "# def delete_all_vectors():\n",
    "#     try:\n",
    "#         qdrant_client.delete(\n",
    "#             collection_name=\"rag_collection\",\n",
    "#             points_selector=rest.PointsSelector(\n",
    "#                 filter=rest.Filter(must=[])  # Match all filter: deletes everything\n",
    "#             )\n",
    "#         )\n",
    "#         print(\"All vectors deleted from the collection.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting all vectors: {e}\")\n",
    "\n",
    "# def delete_existing_chunks(file_id):\n",
    "#     try:\n",
    "#         # Construct filter to match the file_id\n",
    "#         filter_criteria = rest.Filter(\n",
    "#             must=[\n",
    "#                 rest.FieldCondition(\n",
    "#                     key=\"file_id\",\n",
    "#                     match=rest.MatchValue(value=file_id)\n",
    "#                 )\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "#         # Delete chunks based on the filter criteria\n",
    "#         delete_response = qdrant_client.delete(\n",
    "#             collection_name=\"rag_collection\",\n",
    "#             filter=filter_criteria\n",
    "#         )\n",
    "        \n",
    "#         # Print how many chunks were deleted\n",
    "#         print(f\"Deleted {delete_response.result.deleted_count} points for file_id '{file_id}'\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting chunks: {e}\")\n",
    "\n",
    "# def delete_existing_chunks(file_id):\n",
    "#     try:\n",
    "#         qdrant_client.delete(\n",
    "#             collection_name=\"rag_collection\",\n",
    "#             points_selector=rest.FilterSelector(\n",
    "#                 filter=rest.Filter(\n",
    "#                     must=[\n",
    "#                         rest.FieldCondition(\n",
    "#                             key=\"file_id\",\n",
    "#                             match=rest.MatchValue(value=file_id)\n",
    "#                         )\n",
    "#                     ]\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#         print(f\"Deleted old chunks for file_id '{file_id}'\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting chunks: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'rag_collection' deleted successfully.\n",
      "Chunk 1:networks for supervised or discriminative learning but also \n",
      "the deep networks for unsupervised or generative learning, \n",
      "and hybrid learning that can be used to solve a variety of \n",
      "real-world issues according to the nature of problems.\n",
      "Deep learning, unlike traditional machine learning and \n",
      "data mining algorithms, can produce extremely high-level \n",
      "data representations from enormous amounts of raw data. As \n",
      "a result, it has provided an excellent solution to a variety of\n",
      "\n",
      "Chunk 2:and comprehensive view on DL techniques considering the \n",
      "variations in real-world problems and tasks. To achieve \n",
      "our goal, we briefly discuss various DL techniques and \n",
      "present a taxonomy by taking into account three major \n",
      "categories: (i) deep networks for supervised or discrimi-\n",
      "native learning that is utilized to provide a discrimina-\n",
      "tive function in supervised deep learning or classifica-\n",
      "tion applications; (ii) deep networks for unsupervised\n",
      "\n",
      "Chunk 3:application domains. However, designing new techniques \n",
      "or their variants of such discriminative techniques by tak -\n",
      "ing into account model optimization, accuracy, and appli-\n",
      "cability, according to the target real-world application \n",
      "and the nature of the data, could be a novel contribution, \n",
      "which can also be considered as a major future aspect in \n",
      "the area of supervised or discriminative learning.\n",
      "– Deep Networks for Unsupervised or Generative Learn-\n",
      "\n",
      "Chunk 4:complexity, model accuracy, and applicability, selecting \n",
      "an appropriate model for the target application is chal -\n",
      "lenging, and in-depth analysis is needed for better under -\n",
      "standing and decision making.\n",
      "– Deep Networks for Supervised or Discriminative Learn-\n",
      "ing: According to our designed taxonomy of deep learn-\n",
      "ing techniques, as shown in Fig.  6, discriminative archi-\n",
      "tectures mainly include MLP, CNN, and RNN, along \n",
      "with their variants that are applied widely in various\n",
      "\n",
      "Chunk 5:for supervised or discriminative learning tasks, as well as \n",
      "ensuring model accuracy, where unsupervised representation \n",
      "learning can allow for improved classifier generalization.\n",
      "Deep Networks for Hybrid Learning and Other \n",
      "Approaches\n",
      "In addition to the above-discussed deep learning categories, \n",
      "hybrid deep networks and several other approaches such as \n",
      "deep transfer learning (DTL) and deep reinforcement learn-\n",
      "ing (DRL) are popular, which are discussed in the following.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are an intelligent assistant. Use the following context to answer the question accurately.Don’t hallucinate and generate precise answers.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": 0.5,\"k\": 5}),#need to add threshold and should the retrived chunks\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f808ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store(file):\n",
    "    file_id = file.name  # use file name as identifier\n",
    "    status_message = f\"Processing file: {file_id}\\n\"\n",
    "    #delete_existing_chunks(file_id)\n",
    "    delete_collection(collection_name=\"rag_collection\")\n",
    "    status_message += \"All previous chunks deleted from the collection.\\n\"\n",
    "    try:\n",
    "        qdrant_client.create_collection(\n",
    "        collection_name=\"rag_collection\",\n",
    "        vectors_config={\n",
    "            \"size\": 384,\n",
    "            \"distance\": \"Cosine\"\n",
    "        },\n",
    "        optimizers_config={\"default_segment_number\": 1},\n",
    "        on_disk_payload=True\n",
    "    )\n",
    "    except:\n",
    "        pass\n",
    "    text = read_pdf(file)\n",
    "    chunks = split_text(text)\n",
    "    status_message += f\"Text extracted and split into {len(chunks)} chunks.\\n\"\n",
    "    store_embeddings(chunks, file_id)\n",
    "    status_message += f\"Successfully indexed {len(chunks)} chunks into the vectorstore.\"\n",
    "    return status_message\n",
    "\n",
    "\n",
    "def ask_question(query):\n",
    "    #response = qa_chain.run(query)\n",
    "    #return response\n",
    "    response = qa_chain({\"query\": query})\n",
    "    answer = response[\"result\"]\n",
    "    sources = response[\"source_documents\"]\n",
    "\n",
    "    chunks_text = \"\\n\\n\".join([f\"Chunk {i+1}:{doc.page_content}\" for i, doc in enumerate(sources)])\n",
    "\n",
    "    # Combine answer + chunks to display\n",
    "    full_output = f\" Output:\\n{answer}\\n\\n Retrieved Chunks:\\n{chunks_text}\"\n",
    "    print(chunks_text)\n",
    "    return full_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb9931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'rag_collection' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2037/2493502145.py:30: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:India is a land of diverse cultures, rich heritage, and vibrant traditions. Here's a detailed \n",
      "overview of India's culture and heritage: \n",
      "India: A Tapestry of Culture and Heritage \n",
      "Introduction \n",
      "India, known as the cradle of civilization, boasts a history that spans thousands of years. Its \n",
      "culture is a blend of various customs, traditions, and practices that have evolved over \n",
      "centuries. The country's heritage is reﬂected in its architecture, festivals, music, dance,\n",
      "\n",
      "Chunk 2:country's traditions, festivals, music, dance, cuisine, languages, and art reﬂect the \n",
      "harmonious coexistence of various inﬂuences and the vibrant spirit of its people. Exploring \n",
      "India is like embarking on a journey through time, where every corner has a story to tell and \n",
      "every experience is a celebration of life.\n",
      "\n",
      "Chunk 3:landscape. \n",
      "Architecture \n",
      "Indian architecture is renowned for its grandeur and diversity. The country is home to \n",
      "numerous UNESCO World Heritage Sites, including the Taj Mahal, Qutub Minar, and the \n",
      "Ajanta and Ellora Caves. Each region has its distinct architectural style, inﬂuenced by \n",
      "various dynasties and religions. For instance, the Dravidian architecture of South India, \n",
      "characterized by intricately carved temples, contrasts with the Indo-Islamic architecture of \n",
      "North India. \n",
      "Festivals\n",
      "Collection 'rag_collection' deleted successfully.\n",
      "Chunk 1:To summarize, deep learning is a fairly open topic to which \n",
      "academics can contribute by developing new methods or \n",
      "improving existing methods to handle the above-mentioned \n",
      "concerns and tackle real-world problems in a variety of \n",
      "application areas. This can also help the researchers con-\n",
      "duct a thorough analysis of the application’s hidden and \n",
      "unexpected challenges to produce more reliable and realis-\n",
      "tic outcomes. Overall, we can conclude that addressing the\n",
      "\n",
      "Chunk 2:See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/353986944\n",
      "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy,\n",
      "Applications and Research Directions\n",
      "Article    in  SN Comput er Scienc e · August 2021\n",
      "DOI: 10.1007/s42979-021-00815-1\n",
      "CITATIONS\n",
      "1,892READS\n",
      "9,083\n",
      "1 author:\n",
      "Iqbal H. Sark er\n",
      "Edith Co wan Univ ersity\n",
      "240 PUBLICA TIONS    14,666  CITATIONS    \n",
      "SEE PROFILE\n",
      "\n",
      "Chunk 3:why deep learning is important to build data-driven intel-\n",
      "ligent systems. In Section“ Deep Learning Techniques and \n",
      "Applications”, we present our DL taxonomy by taking into \n",
      "account the variations of deep learning tasks and how they \n",
      "are used in solving real-world issues and briefly discuss the \n",
      "techniques with summarizing the potential application areas. \n",
      "In Section “Research Directions and Future Aspects”, we \n",
      "discuss various research issues of deep learning-based mod-\n",
      "Chunk 1:See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/353986944\n",
      "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy,\n",
      "Applications and Research Directions\n",
      "Article    in  SN Comput er Scienc e · August 2021\n",
      "DOI: 10.1007/s42979-021-00815-1\n",
      "CITATIONS\n",
      "1,892READS\n",
      "9,083\n",
      "1 author:\n",
      "Iqbal H. Sark er\n",
      "Edith Co wan Univ ersity\n",
      "240 PUBLICA TIONS    14,666  CITATIONS    \n",
      "SEE PROFILE\n",
      "\n",
      "Chunk 2:To summarize, deep learning is a fairly open topic to which \n",
      "academics can contribute by developing new methods or \n",
      "improving existing methods to handle the above-mentioned \n",
      "concerns and tackle real-world problems in a variety of \n",
      "application areas. This can also help the researchers con-\n",
      "duct a thorough analysis of the application’s hidden and \n",
      "unexpected challenges to produce more reliable and realis-\n",
      "tic outcomes. Overall, we can conclude that addressing the\n",
      "\n",
      "Chunk 3:SEE PROFILE\n",
      "All c ontent f ollo wing this p age was uplo aded b y Iqbal H. Sark er on 13 Mar ch 2024.\n",
      "The user has r equest ed enhanc ement of the do wnlo aded file.\n",
      "Vol.:(0123456789)SN Computer Science (2021) 2:420 \n",
      "https://doi.org/10.1007/s42979-021-00815-1\n",
      "SN Computer Science\n",
      "REVIEW ARTICLE\n",
      "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, \n",
      "Applications and Research Directions\n",
      "Iqbal H. Sarker1,2\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    with gr.Row():\n",
    "        file_input = gr.File(label=\"Upload PDF\")\n",
    "        upload_btn = gr.Button(\"Process File\")\n",
    "    \n",
    "    file_outputs=gr.Textbox(label=\"Status\"),\n",
    "\n",
    "    with gr.Row():\n",
    "        question_input = gr.Textbox(label=\"Ask a question\")\n",
    "        ask_btn = gr.Button(\"Submit\")\n",
    "\n",
    "    answer_output = gr.Textbox(label=\"Answer\")\n",
    "\n",
    "    upload_btn.click(fn=process_and_store, inputs=file_input, outputs=file_outputs)\n",
    "    ask_btn.click(fn=ask_question, inputs=question_input, outputs=answer_output)\n",
    "\n",
    "app.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
